import torch
import torch.nn as nn
import torch.optim as optim
import os
import time
from typing import Any, Mapping

'''
================================================================================
                    ‰∏âÈò∂ÊÆµËß£ËÄ¶ËÆ≠ÁªÉÁ≠ñÁï• (Three-Stage Decoupled Training)
================================================================================

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Stage 1: Physics Only (Áâ©ÁêÜÂ±ÇÂçïÁã¨ËÆ≠ÁªÉ)                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ÁõÆÁöÑ: Âà©Áî®ÊàêÂØπÊï∞ÊçÆÔºåÂçïÁã¨ËÆ≠ÁªÉ AberrationNet ÂáÜÁ°ÆÊãüÂêàÊï∞ÊçÆÈõÜÁöÑÂÖâÂ≠¶ÂÉèÂ∑ÆÁâπÊÄß     ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Êï∞ÊçÆÊµÅ:                                                                     ‚îÇ
‚îÇ    X_gt (Ê∏ÖÊô∞ÂõæÂÉè) ‚îÄ‚îÄ‚ñ∂ PhysicalLayer ‚îÄ‚îÄ‚ñ∂ Y_hat (ÈáçÊ®°Á≥ä)                     ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Loss = MSE(Y_hat, Y) + Œª_coeff √ó ||coeffs||¬≤ + Œª_smooth √ó TV(coeffs)       ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  ÂÜªÁªì: RestorationNet (‚ùÑÔ∏è)     Êõ¥Êñ∞: AberrationNet (üî•)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Stage 2: Restoration with Fixed Physics (Âõ∫ÂÆöÁâ©ÁêÜÂ±ÇËÆ≠ÁªÉÂ§çÂéüÁΩëÁªú)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ÁõÆÁöÑ: Âú®Â∑≤Áü•‰∏îÂáÜÁ°ÆÁöÑÁâ©ÁêÜÊ®°ÂûãÊåáÂØº‰∏ãÔºåËÆ≠ÁªÉÂ§çÂéüÁΩëÁªú                            ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Êï∞ÊçÆÊµÅ:                                                                     ‚îÇ
‚îÇ    Y (Ê®°Á≥äÂõæÂÉè) ‚îÄ‚îÄ‚ñ∂ RestorationNet ‚îÄ‚îÄ‚ñ∂ X_hat ‚îÄ‚îÄ‚ñ∂ PhysicalLayer ‚îÄ‚îÄ‚ñ∂ Y_hat   ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Loss = Œª_sup √ó L1(X_hat, X_gt) + MSE(Y_hat, Y) + Œª_image_reg √ó TV(X_hat)  ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  ÂÜªÁªì: AberrationNet (‚ùÑÔ∏è)      Êõ¥Êñ∞: RestorationNet (üî•)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Stage 3: Joint Fine-tuning (ËÅîÂêàÂæÆË∞É)                                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ÁõÆÁöÑ: ËÅîÂêàÂæÆË∞ÉÔºåÊ∂àÈô§Ê®°ÂùóÈó¥ÁöÑËÄ¶ÂêàËØØÂ∑Æ                                        ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Êï∞ÊçÆÊµÅ:                                                                     ‚îÇ
‚îÇ    Y ‚îÄ‚îÄ‚ñ∂ RestorationNet ‚îÄ‚îÄ‚ñ∂ X_hat ‚îÄ‚îÄ‚ñ∂ PhysicalLayer ‚îÄ‚îÄ‚ñ∂ Y_hat              ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Loss = ÁªºÂêàÊçüÂ§±ÔºàÊâÄÊúâÈ°πÔºâ                                                   ‚îÇ
‚îÇ                                                                              ‚îÇ
‚îÇ  Êõ¥Êñ∞: RestorationNet (üî•) + AberrationNet (üî•)                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
'''
class DualBranchTrainer:
    """
    ‰∏âÈò∂ÊÆµËß£ËÄ¶ËÆ≠ÁªÉÂô® (Three-Stage Decoupled Trainer)

    ÊîØÊåÅ‰∏âÁßçËÆ≠ÁªÉÊ®°Âºè:
    - 'physics_only': ‰ªÖËÆ≠ÁªÉÁâ©ÁêÜÂ±Ç (Stage 1)
    - 'restoration_fixed_physics': Âõ∫ÂÆöÁâ©ÁêÜÂ±ÇËÆ≠ÁªÉÂ§çÂéüÁΩëÁªú (Stage 2)
    - 'joint': ËÅîÂêàËÆ≠ÁªÉÊâÄÊúâÊ®°Âùó (Stage 3)
    """

    VALID_STAGES = ('physics_only', 'restoration_fixed_physics', 'joint')

    def __init__(self,
                 restoration_net,
                 physical_layer,
                 lr_restoration,
                 lr_optics,
                 lambda_sup=1.0,
                 lambda_coeff=0.05,
                 lambda_smooth=0.1,
                 lambda_image_reg=0.0,
                 stage_schedule=None,
                 smoothness_grid_size=16,
                 device='cuda',
                 accumulation_steps=4):

        self.device = device
        self.restoration_net = restoration_net.to(device)
        self.physical_layer = physical_layer.to(device)

        # Access internals for regularization
        self.aberration_net = physical_layer.aberration_net

        # Áã¨Á´ã‰ºòÂåñÂô®
        self.optimizer_W = optim.AdamW(self.restoration_net.parameters(), lr=lr_restoration)
        self.optimizer_Theta = optim.AdamW(self.aberration_net.parameters(), lr=lr_optics)

        # ÂÖºÂÆπÊóßÈÖçÁΩÆÔºàÂ∑≤ÂºÉÁî®ÁöÑÂõ∫ÂÆöÊùÉÈáçÔºå‰ªÖ‰øùÁïôÂ≠óÊÆµÔºâ
        self.lambda_sup = lambda_sup
        self.lambda_coeff = lambda_coeff
        self.lambda_smooth = lambda_smooth
        self.lambda_image_reg = lambda_image_reg

        # ‰∏âÈò∂ÊÆµË∞ÉÂ∫¶ (ÂèØ‰∏∫ dict Êàñ dataclass)
        default_schedule = {
            'stage1_epochs': 80,
            'stage2_epochs': 80,
            'stage3_epochs': 40
        }
        self.stage_schedule: Any = stage_schedule if stage_schedule is not None else default_schedule

        # Âπ≥ÊªëÊ≠£ÂàôÈááÊ†∑ÁΩëÊ†ºÂ§ßÂ∞è
        self.smoothness_grid_size = smoothness_grid_size

        # Ê¢ØÂ∫¶Á¥ØÁßØ
        self.accumulation_steps = max(1, accumulation_steps)
        self.accumulation_counter = 0

        # ÊçüÂ§±ÂáΩÊï∞
        self.criterion_mse = nn.MSELoss()
        self.criterion_l1 = nn.L1Loss()

        # ÂΩìÂâçËÆ≠ÁªÉÈò∂ÊÆµ
        self._current_stage = 'joint'

        # History
        self.history = {
            'loss_total': [], 'loss_data': [], 'loss_sup': [],
            'grad_norm_W': [], 'grad_norm_Theta': []
        }

    # =========================================================================
    #                          Èò∂ÊÆµË∞ÉÂ∫¶‰∏éÂÜªÁªìÁ≠ñÁï•
    # =========================================================================
    def _get_stage(self, epoch: int) -> str:
        """Ê†πÊçÆ epoch(0-indexed) Ëé∑ÂèñÂΩìÂâçÈò∂ÊÆµ"""
        if isinstance(self.stage_schedule, Mapping):
            s1 = self.stage_schedule.get('stage1_epochs', 80)
            s2 = self.stage_schedule.get('stage2_epochs', 80)
        else:
            s1 = getattr(self.stage_schedule, 'stage1_epochs', 80)
            s2 = getattr(self.stage_schedule, 'stage2_epochs', 80)

        if epoch < s1:
            return 'physics_only'
        elif epoch < s1 + s2:
            return 'restoration_fixed_physics'
        return 'joint'

    def _get_stage_weights(self, stage: str):
        """Ê†πÊçÆÈò∂ÊÆµËøîÂõûÂä®ÊÄÅ Loss ÊùÉÈáç"""
        weights = {
            'w_data': 1.0,
            'w_sup': 0.0,
            'w_smooth': 0.0,
            'w_coeff': 0.0,
            'w_img_reg': 0.0
        }

        if stage == 'physics_only':
            weights.update({'w_data': 1.0, 'w_sup': 0.0, 'w_smooth': 0.1, 'w_coeff': 0.01, 'w_img_reg': 0.0})
        elif stage == 'restoration_fixed_physics':
            weights.update({'w_data': 0.1, 'w_sup': 1.0, 'w_smooth': 0.0, 'w_coeff': 0.0, 'w_img_reg': 0.001})
        elif stage == 'joint':
            weights.update({'w_data': 0.5, 'w_sup': 1.0, 'w_smooth': 0.05, 'w_coeff': 0.01, 'w_img_reg': 0.0001})

        return weights

    def _set_trainable(self, stage: str):
        """Ê†πÊçÆÈò∂ÊÆµÂø´ÈÄüÂÜªÁªì/Ëß£ÂÜªÁΩëÁªúÔºåÂπ∂ÂàáÊç¢ train/eval Ê®°Âºè"""
        if stage == 'physics_only':
            for p in self.restoration_net.parameters():
                p.requires_grad = False
            for p in self.aberration_net.parameters():
                p.requires_grad = True
            self.restoration_net.eval()
            self.physical_layer.train()
        elif stage == 'restoration_fixed_physics':
            for p in self.restoration_net.parameters():
                p.requires_grad = True
            for p in self.aberration_net.parameters():
                p.requires_grad = False
            self.restoration_net.train()
            self.physical_layer.eval()
        elif stage == 'joint':
            for p in self.restoration_net.parameters():
                p.requires_grad = True
            for p in self.aberration_net.parameters():
                p.requires_grad = True
            self.restoration_net.train()
            self.physical_layer.train()
        else:
            raise ValueError(f"Invalid stage '{stage}'. Must be one of {self.VALID_STAGES}")

    def set_stage(self, stage: str):
        """ÂÖºÂÆπÊóßÊµÅÁ®ãÁöÑÊâãÂä®ËÆæÁΩÆÔºà‰ªçÂèØÁî®Ôºâ"""
        if stage not in self.VALID_STAGES:
            raise ValueError(f"Invalid stage '{stage}'. Must be one of {self.VALID_STAGES}")
        self._current_stage = stage
        self._set_trainable(stage)

    def get_stage(self, epoch: int) -> str:
        return self._get_stage(epoch)

    def get_stage_weights(self, epoch: int):
        return self._get_stage_weights(self._get_stage(epoch))

    # =========================================================================
    #                              Ê†∏ÂøÉËÆ≠ÁªÉÊ≠•È™§
    # =========================================================================
    def train_step(self, Y_blur, X_gt, epoch, crop_info=None):
        """
        ÊâßË°å‰∏Ä‰∏™ËÆ≠ÁªÉÊ≠•È™§ÔºåÂÜÖÈÉ®Ê†πÊçÆ epoch Ëá™Âä®ÂàáÊç¢Èò∂ÊÆµÂπ∂ÂàÜÈÖçÂä®ÊÄÅ Loss ÊùÉÈáç„ÄÇ
        """
        current_stage = self._get_stage(epoch)
        self._current_stage = current_stage
        self._set_trainable(current_stage)

        weights = self._get_stage_weights(current_stage)
        w_data = weights['w_data']
        w_sup = weights['w_sup']
        w_smooth = weights['w_smooth']
        w_coeff = weights['w_coeff']
        w_img_reg = weights['w_img_reg']

        Y_blur = Y_blur.to(self.device)
        X_gt = X_gt.to(self.device)
        if crop_info is not None:
            crop_info = crop_info.to(self.device)

        # Ê¢ØÂ∫¶Á¥ØÁßØÔºö‰ªÖÂú®Á¨¨‰∏Ä‰∏™Á¥ØÁßØÊ≠•È™§Ê∏ÖÈô§Ê¢ØÂ∫¶
        if self.accumulation_counter == 0:
            if current_stage == 'physics_only':
                self.optimizer_Theta.zero_grad()
            elif current_stage == 'restoration_fixed_physics':
                self.optimizer_W.zero_grad()
            else:
                self.optimizer_W.zero_grad()
                self.optimizer_Theta.zero_grad()

        # ========================== Forward & Loss ===========================
        loss_data = torch.tensor(0.0, device=self.device)
        loss_sup = torch.tensor(0.0, device=self.device)
        loss_coeff = torch.tensor(0.0, device=self.device)
        loss_smooth = torch.tensor(0.0, device=self.device)
        loss_image_reg = torch.tensor(0.0, device=self.device)

        # Stage 1: ‰ªÖÁâ©ÁêÜÂ±Ç
        if current_stage == 'physics_only':
            Y_reblur = self.physical_layer(X_gt, crop_info=crop_info)
            loss_data = self.criterion_mse(Y_reblur, Y_blur)

            if w_coeff > 0 or w_smooth > 0:
                coords = self.physical_layer.get_patch_centers(
                    Y_blur.shape[2], Y_blur.shape[3], self.device
                )
                if coords.shape[0] > 64:
                    indices = torch.randperm(coords.shape[0])[:64]
                    coords = coords[indices]
                coeffs = self.aberration_net(coords)
                if w_coeff > 0:
                    loss_coeff = torch.mean(coeffs**2)
                if w_smooth > 0:
                    loss_smooth = self.physical_layer.compute_coefficient_smoothness(self.smoothness_grid_size)

        # Stage 2/3: Â§çÂéüÁΩëÁªúÂèÇ‰∏é
        else:
            X_hat = self.restoration_net(Y_blur)
            Y_reblur = self.physical_layer(X_hat, crop_info=crop_info)
            loss_data = self.criterion_mse(Y_reblur, Y_blur)
            loss_sup = self.criterion_l1(X_hat, X_gt)

            if w_img_reg > 0:
                loss_image_reg = self.compute_image_tv_loss(X_hat)

            if current_stage == 'joint' and (w_coeff > 0 or w_smooth > 0):
                coords = self.physical_layer.get_patch_centers(
                    Y_blur.shape[2], Y_blur.shape[3], self.device
                )
                if coords.shape[0] > 64:
                    indices = torch.randperm(coords.shape[0])[:64]
                    coords = coords[indices]
                coeffs = self.aberration_net(coords)
                if w_coeff > 0:
                    loss_coeff = torch.mean(coeffs**2)
                if w_smooth > 0:
                    loss_smooth = self.physical_layer.compute_coefficient_smoothness(self.smoothness_grid_size)

        # ========================== Weighted Loss ============================
        loss_data_w = w_data * loss_data
        loss_sup_w = w_sup * loss_sup
        loss_coeff_w = w_coeff * loss_coeff
        loss_smooth_w = w_smooth * loss_smooth
        loss_image_reg_w = w_img_reg * loss_image_reg

        total_loss = loss_data_w + loss_sup_w + loss_coeff_w + loss_smooth_w + loss_image_reg_w

        scaled_loss = total_loss / self.accumulation_steps
        scaled_loss.backward()

        # ========================== Optimizer Step ============================
        self.accumulation_counter += 1
        should_step = (self.accumulation_counter >= self.accumulation_steps)

        gn_W = torch.tensor(0.0, device=self.device)
        gn_Theta = torch.tensor(0.0, device=self.device)

        if should_step:
            if current_stage == 'physics_only':
                gn_Theta = nn.utils.clip_grad_norm_(self.aberration_net.parameters(), 1.0)
                self.optimizer_Theta.step()
            elif current_stage == 'restoration_fixed_physics':
                gn_W = nn.utils.clip_grad_norm_(self.restoration_net.parameters(), 5.0)
                self.optimizer_W.step()
            else:
                gn_W = nn.utils.clip_grad_norm_(self.restoration_net.parameters(), 5.0)
                gn_Theta = nn.utils.clip_grad_norm_(self.aberration_net.parameters(), 1.0)
                self.optimizer_W.step()
                self.optimizer_Theta.step()

            self.accumulation_counter = 0

            self.history['loss_total'].append(total_loss.item())
            self.history['loss_data'].append(loss_data_w.item())
            self.history['grad_norm_W'].append(gn_W.item() if isinstance(gn_W, torch.Tensor) else gn_W)
            self.history['grad_norm_Theta'].append(gn_Theta.item() if isinstance(gn_Theta, torch.Tensor) else gn_Theta)

        return {
            'loss': total_loss.item(),
            'loss_data': loss_data_w.item(),
            'loss_sup': loss_sup_w.item(),
            'loss_coeff': loss_coeff_w.item(),
            'loss_smooth': loss_smooth_w.item(),
            'loss_image_reg': loss_image_reg_w.item(),
            'loss_data_raw': loss_data.item(),
            'loss_sup_raw': loss_sup.item(),
            'loss_coeff_raw': loss_coeff.item(),
            'loss_smooth_raw': loss_smooth.item(),
            'loss_image_reg_raw': loss_image_reg.item(),
            'grad_W': gn_W.item() if isinstance(gn_W, torch.Tensor) else gn_W,
            'grad_Theta': gn_Theta.item() if isinstance(gn_Theta, torch.Tensor) else gn_Theta,
            'stage': current_stage
        }

    def compute_image_tv_loss(self, img):
        """
        Compute Total Variation (TV) loss on the image.
        L_tv = mean(|dI/dx| + |dI/dy|)
        """
        B, C, H, W = img.shape
        dy = torch.abs(img[:, :, 1:, :] - img[:, :, :-1, :]).mean()
        dx = torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1]).mean()
        return dy + dx

    def save_checkpoint(self, path):
        torch.save({
            'restoration_net': self.restoration_net.state_dict(),
            'aberration_net': self.aberration_net.state_dict(),
            'optimizer_W': self.optimizer_W.state_dict(),
            'optimizer_Theta': self.optimizer_Theta.state_dict()
        }, path)
