
=== Test 4: NewBP Integration & Training Loop ===
Using device: cpu

--- Testing Standard Implementation ---
Forward Output Shape: torch.Size([2, 3, 64, 64])
Loss: 1.244568
Input Gradient Norm: 0.007486

--- Testing NewBP Implementation ---
Forward Pass Difference (Std vs NewBP): 0.000000e+00
[SUCCESS] Forward pass matches Standard Implementation
Loss: 1.244568
Input Gradient Norm: 0.007486
[SUCCESS] NewBP Backward Pass successful (Gradient flow confirmed)
Parameter Gradient Norm sum: 3.981965
[SUCCESS] Gradients propagated to AberrationNet parameters

=== Integration Test Complete ===
